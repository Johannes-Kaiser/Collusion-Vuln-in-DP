{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9269e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/vol/miltank/users/kaiserj/Clipping_vs_Sampling/\")\n",
    "import shutil\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from itertools import combinations\n",
    "import statsmodels.formula.api as smf\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "from opacus_new import PrivacyEngine\n",
    "from opacus_new.accountants import RDPAccountant\n",
    "from opacus_new.validators.module_validator import ModuleValidator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from types import SimpleNamespace\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Secure RNG turned off.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b9b9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a custom dataset class\n",
    "\n",
    "class customSmallDS(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.tensors = [data, target]\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, num_samples=10_000, height=32, width=32, num_features=3, transform=None, target_transform=None):\n",
    "        self.data = (255 * np.random.rand(num_samples, height, width, num_features)).astype(np.uint8)\n",
    "        self.targets = torch.randint(0, 10, (num_samples,))\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.dataset = customSmallDS(self.data, self.targets)\n",
    "        self.indices = list(range(num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return sample, target\n",
    "    \n",
    "@classmethod\n",
    "def from_dataset(cls, dataset):\n",
    "    # If we got a Subset, unwrap it\n",
    "    if isinstance(dataset, torch.utils.data.Subset):\n",
    "        data = dataset.dataset.data[dataset.indices]\n",
    "        targets = dataset.dataset.targets[dataset.indices]\n",
    "        transform = getattr(dataset.dataset, \"transform\", None)\n",
    "        target_transform = getattr(dataset.dataset, \"target_transform\", None)\n",
    "    else:\n",
    "        data = dataset.data\n",
    "        targets = dataset.targets\n",
    "        transform = getattr(dataset, \"transform\", None)\n",
    "        target_transform = getattr(dataset, \"target_transform\", None)\n",
    "\n",
    "    return cls(\n",
    "        data=data,\n",
    "        targets=targets,\n",
    "        transform=transform,\n",
    "        target_transform=target_transform,\n",
    "    )\n",
    "\n",
    "## Define a custom model class\n",
    "\n",
    "class DummyResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet18(num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "\n",
    "def make_private(model, train_loader, pp_budgets, args):\n",
    "    modulevalidator = ModuleValidator()\n",
    "    model = modulevalidator.fix_and_validate(model)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    privacy_engine = PrivacyEngine(accountant=args.accountant,\n",
    "                                   individualize=args.individualize,\n",
    "                                   weights=args.weights,\n",
    "                                   pp_budgets=pp_budgets)\n",
    "    if args.adapt_weights_to_budgets:\n",
    "        private_model, private_optimizer, private_loader = privacy_engine \\\n",
    "            .make_private_with_epsilon(module=model,\n",
    "                                       optimizer=optimizer,\n",
    "                                       data_loader=train_loader,\n",
    "                                       target_epsilon=min(pp_budgets),\n",
    "                                       target_delta=args.target_delta,\n",
    "                                       epochs=args.epochs,\n",
    "                                       max_grad_norm=args.max_grad_norm,\n",
    "                                       optimal=True,\n",
    "                                       max_alpha=10_000)\n",
    "                                    #    numeric=True)\n",
    "    else:\n",
    "        private_model, private_optimizer, private_loader = privacy_engine \\\n",
    "            .make_private(module=model,\n",
    "                          optimizer=optimizer,\n",
    "                          data_loader=train_loader,\n",
    "                          noise_multiplier=args.noise_multiplier,\n",
    "                          max_grad_norm=args.max_grad_norm)\n",
    "\n",
    "    if args.individualize == 'clipping':\n",
    "        print(\"Maxgradnorm:\", privacy_engine.weights)\n",
    "        print(\"budgets:\", list(np.unique(np.array(pp_budgets), return_counts=True)))\n",
    "        print(\"noise_multiplier:\", [private_optimizer.noise_multiplier * args.max_grad_norm/priv for priv in privacy_engine.weights])\n",
    "        print(\"weights:\", privacy_engine.weights)\n",
    "        print()\n",
    "        return{\n",
    "            \"budgets\": list(np.unique(np.array(pp_budgets))),\n",
    "            \"max_grad_norms\": privacy_engine.weights,\n",
    "            \"sample_rate\": [1 / len(private_loader)] * len(privacy_engine.weights),\n",
    "            \"noise_multiplier\": [private_optimizer.noise_multiplier for priv in privacy_engine.weights] \n",
    "        }\n",
    "    elif args.individualize == 'sampling':\n",
    "        return{\n",
    "            \"budgets\": list(np.unique(np.array(pp_budgets))),\n",
    "            \"max_grad_norms\": [args.max_grad_norm] * len(privacy_engine.weights),\n",
    "            \"sample_rate\":privacy_engine.weights,\n",
    "            \"noise_multiplier\":[private_optimizer.noise_multiplier] * len(privacy_engine.weights)\n",
    "        }\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fffdd77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_label(portions: str, bold_index: int) -> str:\n",
    "    \"\"\"\n",
    "    rf\"$\\mathbf{{{math.ceil(p[0]*100)}\\%}}$/{math.ceil(p[1]*100)}%\"\n",
    "    Creates a LaTeX formatted label for plots, highlighting one portion.\n",
    "    Example: [0.2, 0.8] with bold_index=0 -> \"$\\\\mathbf{20\\\\%}$/80%\"\n",
    "    \"\"\"\n",
    "    portions = [float(portions), 1 - float(portions)]\n",
    "    if bold_index == 0:\n",
    "        labels = rf\"$\\mathbf{{{math.ceil(portions[0]*100)}\\%}}$/{math.ceil(portions[1]*100)}%\"\n",
    "    else:\n",
    "        labels = rf\"{math.ceil(portions[0]*100)}%/$\\mathbf{{{math.ceil(portions[1]*100)}\\%}}$\"\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "643e5bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epsilon_delta_curves(sr, nm, cw, num_steps, budget_keys, portion_keys, colors, target_delta, target_epsilons):\n",
    "    \"\"\"\n",
    "    Creates a plot showing the Epsilon vs. Delta privacy curve for each\n",
    "    experimental portion, colored consistently.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # Store handles and labels as flat lists\n",
    "    handles = []\n",
    "    labels = []\n",
    "    linewidth = 1.2\n",
    "\n",
    "    for i, budget in enumerate(budget_keys):\n",
    "        for p_idx, portion_name in enumerate(portion_keys):\n",
    "            epsilons, deltas = _compute_epsilon_delta_curve(\n",
    "                noise_multiplier=nm[i][p_idx]/cw[i][p_idx],\n",
    "                deltas=np.logspace(-14, -1, 100),\n",
    "                iterations=num_steps[i][p_idx],\n",
    "                sampling_rate=sr[i][p_idx],\n",
    "                clipping_norm=1,\n",
    "            )\n",
    "            label = generate_latex_label(portion_name, i)\n",
    "            plot_handle, = ax.plot(epsilons, deltas, color=colors[i][p_idx + 3], alpha=0.9, linewidth=linewidth, label=label)\n",
    "            \n",
    "            # Append handles and labels in the desired order\n",
    "            handles.append(plot_handle)\n",
    "            labels.append(label)\n",
    "\n",
    "\n",
    "    target_delta = target_delta\n",
    "    target_epsilons = target_epsilons\n",
    "    rest_handles = []\n",
    "    rest_labels = []\n",
    "\n",
    "    if target_delta:\n",
    "        plot_handle = ax.axhline(target_delta, color='red', linestyle='--', linewidth=linewidth, label='Target $\\delta$')\n",
    "        rest_handles.append(plot_handle)\n",
    "        rest_labels.append('Target $\\delta$')\n",
    "    \n",
    "    if target_epsilons:\n",
    "        for i, eps in enumerate(target_epsilons):\n",
    "            plot_handle = ax.axvline(eps, color='red', linestyle=':', linewidth=linewidth, label='Target $\\epsilon$' if i == 0 else None)\n",
    "            if i == 0:\n",
    "                rest_handles.append(plot_handle)\n",
    "                rest_labels.append('Target $\\epsilon$')\n",
    "    \n",
    "    # Correctly order and flatten the lists for the two-column legend\n",
    "    handles_all = handles[:int(len(handles)/2)] + rest_handles + handles[int(len(handles)/2):]\n",
    "    labels_all = labels[:int(len(handles)/2)] + rest_labels + labels[int(len(handles)/2):]\n",
    "    \n",
    "    # Add dummy entries to the right column to align the last items correctly\n",
    "    for _ in rest_handles:\n",
    "        handles_all.append(mpl.lines.Line2D([0], [0], color='none'))\n",
    "        labels_all.append(\"\")\n",
    "    \n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(\"Epsilon ($\\epsilon$)\")\n",
    "    ax.set_ylabel(\"Delta ($\\delta$, log scale)\")\n",
    "    \n",
    "    # Pass the correctly ordered flat lists to the legend\n",
    "    ax.legend(handles=handles_all, labels=labels_all, ncol=2, loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "    for ext in [\"png\", \"svg\"]: \n",
    "        fig.savefig(f\"/vol/miltank/users/kaiserj/Clipping_vs_Sampling/extra_figs/epsilon_delta_curve_1.{ext}\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9b3e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_epsilon_delta_curve(noise_multiplier, deltas, iterations, sampling_rate, clipping_norm):\n",
    "    from dp_accounting.pld import privacy_loss_distribution\n",
    "    \"\"\"\n",
    "    Compute epsilon for a range of deltas using the RDP accountant.\n",
    "    \"\"\"\n",
    "    def compute_epsilon(noise_multiplier, delta, iterations, sampling_rate, clipping_norm):\n",
    "        accountant = RDPAccountant()\n",
    "        accountant.history = [(noise_multiplier/clipping_norm, sampling_rate, int(iterations))]\n",
    "        return accountant.get_epsilon(delta)\n",
    "    epsilons = []\n",
    "    deltas2 = []\n",
    "    for delta in deltas:\n",
    "        epsilon = compute_epsilon(noise_multiplier, delta, iterations, sampling_rate, clipping_norm)\n",
    "        epsilons.append(epsilon)\n",
    "        deltas2.append(delta)\n",
    "    return epsilons, deltas2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1391d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_tradeoff_envelope(params: Dict, alphas: np.ndarray) -> np.ndarray:\n",
    "    from dp_accounting.pld import privacy_loss_distribution\n",
    "    def profile2tradeoff(alpha, eps, delta):\n",
    "        term1 = 1.0 - delta - np.exp(eps)*alpha\n",
    "        term2 = (1.0 - delta - alpha)*np.exp(-eps)\n",
    "        return np.maximum(0.0, np.maximum(term1, term2))\n",
    "\n",
    "    def ADP2fDP(alphas, epsilons, deltas):\n",
    "        betas = []\n",
    "        for alpha in alphas:\n",
    "            B = profile2tradeoff(alpha, np.asarray(epsilons), np.asarray(deltas))\n",
    "            betas.append(np.max(B))\n",
    "        return betas\n",
    "    \"\"\"Computes the trade-off curve for given params using PLD.\"\"\"\n",
    "    sigma = params[\"noise_multiplier\"]\n",
    "    p = params[\"sample_rate\"]\n",
    "    N = params[\"steps\"]\n",
    "    epsila = np.linspace(-10, 10, 10000)\n",
    "    mech = privacy_loss_distribution.from_gaussian_mechanism(\n",
    "        standard_deviation=sigma,\n",
    "        sampling_prob=p).self_compose(N)\n",
    "    deltas = mech.get_delta_for_epsilon(epsila)\n",
    "    tradeoff = ADP2fDP(alphas, epsila, deltas)\n",
    "\n",
    "    return alphas, tradeoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fad3437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_privacy_tradeoff(nm, num_steps, sr, cw, budgets_keys, portion_keys, colors):\n",
    "    \"\"\"\n",
    "    Creates a grid showing the Type I vs. Type II error trade-off and\n",
    "    the resulting privacy advantage for each budget.\n",
    "    \"\"\"\n",
    "    n_budgets = len(budget_keys)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 4 * 1), squeeze=False)\n",
    "    alphas = np.linspace(0, 1, 10000)\n",
    "\n",
    "    for r, budget_key in enumerate([budget_keys[0]]):\n",
    "        ax_curve, ax_bar = axes[r, 0], axes[r, 1]\n",
    "        advantages = {}\n",
    "        \n",
    "        for p_idx, portion_name in enumerate(portion_keys):\n",
    "            params = {\n",
    "                \"noise_multiplier\": float(nm[r][p_idx]) / float(cw[r][p_idx]),\n",
    "                \"steps\": int(num_steps[r][p_idx]),\n",
    "                \"sample_rate\": float(sr[r][p_idx]),\n",
    "            }\n",
    "            alphas, envelope = _compute_tradeoff_envelope(params, alphas)\n",
    "            \n",
    "            # Plotting\n",
    "            label = generate_latex_label(portion_name, 1 if r == 1 else 0)\n",
    "            # test = np.argmax(envelope, axis=0)\n",
    "            # envelope = np.max(envelope, axis=0)\n",
    "            print(f\"r={r}, p_idx={p_idx}, {colors.shape}\")\n",
    "            ax_curve.plot(alphas, envelope, color=colors[r][p_idx + 3], linewidth=2, label=label)\n",
    "\n",
    "            # from scipy.ndimage import gaussian_filter1d\n",
    "            # smoothed_envelope = gaussian_filter1d(envelope, sigma=10)  # adjust sigma for more/less smoothing\n",
    "            # ax_curve.plot(alpha_grid, smoothed_envelope, color=\"black\", linewidth=0.2, label=label)\n",
    "\n",
    "            # Advantage calculation\n",
    "            trivial = 1 - alphas\n",
    "            diff = trivial - envelope\n",
    "            max_idx = np.argmax(np.nan_to_num(diff))\n",
    "            advantages[p_idx] = diff[max_idx]\n",
    "            ax_curve.plot([alphas[max_idx], alphas[max_idx]], [envelope[max_idx], trivial[max_idx]],\n",
    "                            color=colors[r][p_idx + 3], linestyle=\":\", linewidth=1)\n",
    "\n",
    "        # Format curve plot\n",
    "        ax_curve.plot([0, 1], [1, 0], 'k:', label=\"_nolegend_\")\n",
    "        ax_curve.set_title(f\"Budget ($\\epsilon$) = {budget_key}\")\n",
    "        ax_curve.set_xlabel(\"Type I error $\\\\alpha$\")\n",
    "        ax_curve.set_ylabel(\"Type II error $\\\\beta$\")\n",
    "        ax_curve.grid(True)\n",
    "        ax_curve.legend()\n",
    "\n",
    "        # Format bar plot\n",
    "        x_labels = [generate_latex_label(portion_name, 1 if r == 1 else 0) for portion_name in portion_keys]\n",
    "        y_values = list(advantages.values())\n",
    "        colors_barplot = colors[r][3:]\n",
    "        ax_bar.bar(range(len(x_labels)), y_values, color=colors_barplot, width=0.5)\n",
    "        ax_bar.set_ylabel(\"Advantage\")\n",
    "        ax_bar.set_xticks(range(len(x_labels)))\n",
    "        ax_bar.set_xticklabels(x_labels, rotation=90)\n",
    "        margin = 0.1 * (max(y_values) - min(y_values)) if len(y_values) > 1 and max(y_values) != min(y_values) else 0.1\n",
    "        ax_bar.set_ylim(min(y_values) - margin, max(y_values) + margin)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    for ext in [\"png\", \"svg\"]: \n",
    "        fig.savefig(f\"/vol/miltank/users/kaiserj/Clipping_vs_Sampling/extra_figs/trade_off_curves_1.{ext}\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "567851c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'budgets': [np.int64(3), np.int64(15)], 'max_grad_norms': [1, 1], 'sample_rate': [np.float64(0.0032958993688225746), np.float64(0.014976502396166325)], 'noise_multiplier': [0.6370068896484375, 0.6370068896484375]}\n",
      "\n",
      "{'budgets': [np.int64(3), np.int64(15)], 'max_grad_norms': [1, 1], 'sample_rate': [np.float64(0.004333497025072575), np.float64(0.01815796084702015)], 'noise_multiplier': [0.688006640625, 0.688006640625]}\n",
      "\n",
      "{'budgets': [np.int64(3), np.int64(15)], 'max_grad_norms': [1, 1], 'sample_rate': [np.float64(0.0058479318395257), np.float64(0.02288818545639515)], 'noise_multiplier': [0.7625062768554687, 0.7625062768554687]}\n",
      "\n",
      "{'budgets': [np.int64(3), np.int64(15)], 'max_grad_norms': [1, 1], 'sample_rate': [np.float64(0.008193970657885075), np.float64(0.03057861514389515)], 'noise_multiplier': [0.8865056713867188, 0.8865056713867188]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = SimpleNamespace(\n",
    "    accountant=\"rdp\",  # Options: \"rdp\", \"gdp\", etc.\n",
    "    individualize=\"sampling\", # \"sampling\",  # Options: None, \"clipping\", \"sampling\"\n",
    "    weights=None,  # Should be a list or None\n",
    "    adapt_weights_to_budgets=True,  # Whether to adapt weights to budgets\n",
    "    target_delta=1e-3,  # Default delta value for DP\n",
    "    epochs=50,  # Number of training epochs\n",
    "    max_grad_norm=1,  # Clipping norm for DP-SGD\n",
    "    # noise_multiplier=1.0,  # Noise multiplier for DP\n",
    "    n_data=10000,  # Number of data points\n",
    ")\n",
    "\n",
    "\n",
    "nm, sr, cw, num_steps = [], [], [], []\n",
    "portions = [0.2, 0.4, 0.6, 0.8]\n",
    "eps_1 = 3\n",
    "epsilon_2 = 15\n",
    "for portion in portions:\n",
    "    dummy_train_loader = DataLoader(CustomDataset(num_samples=args.n_data), batch_size=128, shuffle=True)\n",
    "    dummy_model = DummyResNet18()\n",
    "    n_portion = int(portion * args.n_data)\n",
    "    pp_budgets = [eps_1] * n_portion + [epsilon_2] * (args.n_data - n_portion)\n",
    "    parameters = make_private(dummy_model, dummy_train_loader, pp_budgets, args)\n",
    "    print(parameters)\n",
    "    print()\n",
    "    nm.append(parameters[\"noise_multiplier\"])\n",
    "    sr.append(parameters[\"sample_rate\"])\n",
    "    cw.append(parameters[\"max_grad_norms\"])\n",
    "    num_steps.append([args.epochs * len(dummy_train_loader), args.epochs * len(dummy_train_loader)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "92389d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nm_t = torch.tensor(nm).t()\n",
    "sr_t = torch.tensor(sr).t()\n",
    "cw_t = torch.tensor(cw).t()\n",
    "num_steps_t = torch.tensor(num_steps).t()\n",
    "sr_t = torch.tensor(sr).t()\n",
    "cw_t = torch.tensor(cw).t()\n",
    "num_steps_t = torch.tensor(num_steps).t()\n",
    "portion_keys = [str(por) for por in portions]\n",
    "budget_keys = [eps_1, epsilon_2] \n",
    "target_delta = args.target_delta\n",
    "target_epsilons = budget_keys\n",
    "cmaps = [plt.get_cmap('Oranges'), plt.get_cmap('Blues')]\n",
    "colors = [[cmap(x) for x in np.linspace(0, 1, len(portion_keys) + 3)] for cmap in cmaps]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "19a41f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epsilon_delta_curves(sr_t, nm_t, cw_t, num_steps_t, budget_keys, portion_keys, colors, target_delta, target_epsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5b116993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=0, p_idx=0, (2, 7, 4)\n",
      "r=0, p_idx=1, (2, 7, 4)\n",
      "r=0, p_idx=2, (2, 7, 4)\n",
      "r=0, p_idx=3, (2, 7, 4)\n"
     ]
    }
   ],
   "source": [
    "plot_privacy_tradeoff(nm_t, num_steps_t, sr_t, cw_t, budget_keys, portion_keys, np.array(colors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
